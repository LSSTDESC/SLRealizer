{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.modeling.models import Sersic2D, Gaussian2D\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expressing a 2D Sersic profile as a Mixture of Gaussians (MoG)\n",
    "\n",
    "Author: Ji Won Park (jiwoncpark)\n",
    "\n",
    "Many survey catalogs model the galaxy bulge as a de Vaucouleurs profile and the galaxy disk as an exponential profile. These profiles belong to the more general class of *Sersic profiles* indexed by $n$, which controls the profile's degree of curvature, or how fast the intensity falls off from the center. The de Vaucouleurs profile is the case when $n=4$ and exponential, $n=1$.\n",
    "\n",
    "The Sersic distribution is commonly expressed as:\n",
    "$I(r) = I_e \\exp(-b_n [(r/r_0)^{1/n} - 1])$, where $b_n$ can be obtained by numerically solving $\\Gamma(2 n) = 2\\gamma(b_n, 2n)$ and the intensity equals $I_e$ at the half-light radius $r_0$.\n",
    "\n",
    "In this tutorial, we use [Hogg and Lang 2013](http://adsabs.harvard.edu/cgi-bin/bib_query?arXiv:1210.6563) (HL13) to approximate this as a mixture, i.e. a linear superposition, of Gaussian distributions. Doing this allows SLRealizer to take advantage of all that Gaussians have to offer--for instance, we can simplify the PSF convolution using the fact that convolving a Gaussian with a Gaussian yields another Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first get the values of $b_4$ and $b_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gammaincinv\n",
    "b4 = gammaincinv(8, 0.5) # for de vaucouleurs\n",
    "b1 = gammaincinv(2, 0.5) # for exponential\n",
    "\n",
    "print(b4, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. de Vaucouleurs ~ MoG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a change of variable and some scaling on the HL13 formulation, we have that the following de Vaucouleurs distribution\n",
    "\n",
    "$I_4(r) = \\frac{1}{C_4} \\exp(-b_1[(r/r_0)^{1/4} - 1])$ can be approximated by\n",
    "\n",
    "$\\tilde{I}_4(r) = \\frac{r_0^2}{C_4} \\sum_{m=1}^{M_1} c_m N(r ; 0, v_m r_0^2 I) $ where\n",
    "\n",
    "$C_4 = \\frac{40320 \\pi r_0^2 e^{b_4}}{b_4^8}$ is a normalization constant to ensure both $I_4$ and $\\tilde{I}_4$ integrate to unity.\n",
    "\n",
    "The optimal fit values for the variances $v_m$ and the weights $c_m$ for a given mixture size $M_4$ are listed in Table 1 of HL13. We use $M_4 = 6$, the smallest mixture size listed, and the corresponding $\\sqrt{v_m}$ and $c_m$ values can be found in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_mog_params = {}\n",
    "dev_mog_params['stds'] = np.array([0.00263, 0.01202, 0.04031, 0.12128, 0.36229, 1.23604]) # sqrt(v_m)\n",
    "dev_mog_params['weights'] = np.array([0.01308, 0.12425, 0.63551,  2.22560, 5.63989, 9.81523]) # c_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Test of Flux\n",
    "In all tests to follow, we put $r_0=1.3$. Let's check that the flux of $\\tilde{I}_4$ equals 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0 = 1.3\n",
    "\n",
    "# Compare zeroth moments (flux)\n",
    "C4 = 40320.0*np.pi*r0**2.0*np.exp(b4)/b4**8.0 # i.e. C4 found by analytically integrating $I_4$\n",
    "dev_mog_flux = np.sum(dev_mog_params['weights'])*r0**2.0/C4\n",
    "print(dev_mog_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Test of Second Moment\n",
    "Note that all odd moments will be zero, since our profiles are circularly symmetric. We obtain the second moment (either diagonal entry of the second-moment matrix) of $I_1$ analytically and compare it with the that of $\\tilde{I}_1$, which is the weighted sum of the second moments of its components, i.e. $\\frac{r_0^2}{C_4} \\sum_{m=1}^{M_4} c_m (v_m r_0^2) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original exponential\n",
    "dev_2nd_mom = np.pi*5230697472000.0*np.exp(b4)*r0**4.0/(b4**16.0)/C4 # analytically derived\n",
    "#TODO: this is wrong, based on numerical second moment estimation from image grid\n",
    "\n",
    "# MoG\n",
    "dev_mog_2nd_mom = np.sum(dev_mog_params['weights']*dev_mog_params['stds']**2.0)*r0**4.0/C4\n",
    "print(dev_2nd_mom, dev_mog_2nd_mom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Sanity Check Using Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = 0.0\n",
    "pixel_scale = 0.001\n",
    "x,y = np.meshgrid(np.arange(-4.0, 4.0, pixel_scale), np.arange(-4.0, 4.0, pixel_scale)) # must extend out to 8 from center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev_hl13(x, y):\n",
    "    return 1.0/C4*np.exp(-b4*((np.sqrt(x**2.0 + y**2.0)/r0)**0.25 - 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_astropy = Sersic2D(amplitude=1.0/C4, r_eff=r0, n=4, x_0=center, y_0=center, ellip=0.0, theta=0.0)\n",
    "dev_hl13_img = dev_hl13(x, y)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.log(dev_hl13_img), origin='lower', interpolation='nearest')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Log Brightness', rotation=270, labelpad=25)\n",
    "#cbar.set_ticks([-1, 0, 1, 2], update_ticks=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_astropy_img = dev_astropy(x, y)\n",
    "#np.save('dev_astropy_img', dev_astropy_img)\n",
    "#np.save('dev_hl13_img', dev_hl13_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(dev_astropy_img, dev_hl13_img)\n",
    "#assert np.isclose(np.sum(dev_hl13_img)*4.0*pixel_scale**2.0, 1.0, rtol=1.e-3)\n",
    "assert dev_hl13(r0, 0.0) == 1.0/C4\n",
    "assert np.max(dev_hl13_img) == 1.0/C4*np.exp(b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dev_mog_img = None\n",
    "for weight, std in list(zip(dev_mog_params['weights'], dev_mog_params['stds'])):\n",
    "    approx = Gaussian2D(amplitude=weight/(2.0*np.pi*(std)**2.0), x_mean=center, y_mean=center, x_stddev=std*r0, y_stddev=std*r0)\n",
    "    if dev_mog_img is None:\n",
    "        dev_mog_img = approx(x, y)\n",
    "    else:\n",
    "        dev_mog_img += approx(x, y)\n",
    "\n",
    "dev_mog_img /= C4\n",
    "np.save('dev_mog_img.txt', dev_mog_img)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.log(dev_mog_img), origin='lower', interpolation='nearest')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Log Brightness', rotation=270, labelpad=25)\n",
    "#cbar.set_ticks([-1, 0, 1, 2], update_ticks=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_residual = (dev_mog_img - dev_hl13_img)/dev_hl13_img\n",
    "plt.imshow(dev_residual, origin='lower', interpolation='nearest')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average discrepancy per pixel is around 76%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(dev_residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exponential ~ MoG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a change of variable and some scaling on the HL13 formulation, we have that the following exponential distribution\n",
    "\n",
    "$I_1(r) = \\frac{1}{C_1} \\exp(-b_1[r/r_0 - 1])$ can be approximated by\n",
    "\n",
    "$\\tilde{I}_1(r) = \\frac{r_0^2}{C_1} \\sum_{m=1}^{M_1} c_m N(r ; 0, v_m r_0^2 I) $ where\n",
    "\n",
    "$C_1 = \\frac{2 \\pi r_0^2 e^{b_1}}{b_1^2}$ is a normalization constant to ensure both $I_1$ and $\\tilde{I}_1$ integrate to unity.\n",
    "\n",
    "The optimal fit values for the variances $v_m$ and the weights $c_m$ for a given mixture size $M_1$ are listed in Table 1 of HL13. We use $M_1 = 4$, the smallest mixture size listed, and the corresponding $\\sqrt{v_m}$ and $c_m$ values can be found in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_mog_params = {}\n",
    "exp_mog_params['stds'] = np.array([0.12068, 0.32730, 0.68542, 1.28089]) # sqrt(v_m)\n",
    "exp_mog_params['weights'] = np.array([0.09733, 1.12804, 4.99846, 5.63632]) # c_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Test of Flux\n",
    "In all tests to follow, we put $r_0=1.3$. Let's check that the flux of $\\tilde{I}_1$ equals 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0 = 1.3\n",
    "\n",
    "# Compare zeroth moments (flux)\n",
    "C1 = 2.0*np.pi*r0**2.0*np.exp(b1)/b1**2.0 # i.e. C1 found by analytically integrating $I_1$\n",
    "exp_mog_flux = np.sum(exp_mog_params['weights'])*r0**2.0/C1\n",
    "print(exp_mog_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Test of Second Moment\n",
    "We obtain the second moment (either diagonal entry of the second-moment matrix) of $I_1$ analytically and compare it with the that of $\\tilde{I}_1$, which is the weighted sum of the second moments of its components, i.e. $\\frac{r_0^2}{C_1} \\sum_{m=1}^{M_1} c_m (v_m r_0^2) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original exponential\n",
    "exp_2nd_mom = np.pi*6.0*np.exp(b1)*r0**4.0/(b1**4.0)/C1 # analytically derived\n",
    "\n",
    "# MoG\n",
    "exp_mog_2nd_mom = np.sum(exp_mog_params['weights']*exp_mog_params['stds']**2.0)*r0**4.0/C1\n",
    "print(exp_2nd_mom, exp_mog_2nd_mom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Sanity Check Using Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = 0.0\n",
    "pixel_scale = 0.001\n",
    "x,y = np.meshgrid(np.arange(0.0, 8.0, pixel_scale), np.arange(0.0, 8.0, pixel_scale)) # must extend out to 8 from center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_hl13(x, y):\n",
    "    return 1.0/C1*np.exp(-b1*(np.sqrt(x**2.0 + y**2.0)/r0 - 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_astropy = Sersic2D(amplitude=1.0/C1, r_eff=r0, n=1, x_0=center, y_0=center, ellip=0.0, theta=0.0)\n",
    "exp_hl13_img = exp_hl13(x, y)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(exp_hl13_img, origin='lower', interpolation='nearest')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Brightness', rotation=270, labelpad=25)\n",
    "#cbar.set_ticks([-1, 0, 1, 2], update_ticks=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_astropy_img = exp_astropy(x, y)\n",
    "np.save('exp_astropy_img', exp_astropy_img)\n",
    "np.save('exp_hl13_img', exp_hl13_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(exp_astropy_img, exp_hl13_img)\n",
    "assert np.isclose(np.sum(exp_hl13_img)*4.0*pixel_scale**2.0, 1.0, rtol=1.e-3)\n",
    "assert exp_hl13(r0, 0.0) == 1.0/C1\n",
    "assert np.max(exp_hl13_img) == 1.0/C1*np.exp(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "exp_mog_img = None\n",
    "for weight, std in list(zip(exp_mog_params['weights'], exp_mog_params['stds'])):\n",
    "    approx = Gaussian2D(amplitude=weight/(2.0*np.pi*(std)**2.0), x_mean=center, y_mean=center, x_stddev=std*r0, y_stddev=std*r0)\n",
    "    if exp_mog_img is None:\n",
    "        exp_mog_img = approx(x, y)\n",
    "    else:\n",
    "        exp_mog_img += approx(x, y)\n",
    "\n",
    "exp_mog_img /= C1\n",
    "np.save('exp_mog_img.txt', exp_mog_img)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(exp_mog_img, origin='lower', interpolation='nearest')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Brightness', rotation=270, labelpad=25)\n",
    "#cbar.set_ticks([-1, 0, 1, 2], update_ticks=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_residual = (exp_mog_img - exp_hl13_img)/exp_hl13_img\n",
    "plt.imshow(exp_residual, origin='lower', interpolation='nearest')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average discrepancy per pixel is around 58%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(exp_residual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
