{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulating the LSST DRP Source Catalog with CosmoDC2Realizer\n",
    "\n",
    "__Author:__ Ji Won Park (@jiwoncpark), __Last Run:__ 2018-12-14 (by @jiwoncpark)\n",
    "\n",
    "__Goals:__\n",
    "- In Part 1 (this notebook), learn how CosmoDC2Realizer emulates the LSST DRP Source Catalog of lensed quasars and contaminants from the CosmoDC2 extragalactic catalog and the truth catalog\n",
    "- In Part 2, visualize sample light curves from the CosmoDC2Realized catalog\n",
    "\n",
    "The following notebook was referenced to access and query the truth catalog:\n",
    "\n",
    "    Scott Daniel's DC2 Tutorial truth_gcr_intro.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from scipy import spatial\n",
    "from scipy.special import gammaincinv\n",
    "import pandas as pd \n",
    "pd.options.display.max_columns = None\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "sys.path.insert(0, '../utils')\n",
    "import utils\n",
    "# For reading in the OpSim database\n",
    "import sqlite3\n",
    "import healpy\n",
    "# For accessing and querying the CosmoDC2 extragalactic catalog and truth catalog\n",
    "#import GCRCatalogs\n",
    "#from GCR import GCRQuery\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About CosmoDC2Realizer\n",
    "\n",
    "CosmoDC2Realizer is a framework that emulates the LSST DRP Source Catalog. It takes in two DC2 catalogs--the extragalactic and truth catalogs, which provide properties of extended galaxy sources and point sources (e.g. stars, AGNs), respectively--and the Opsim database, which provide the per-visit observation conditions. \n",
    "\n",
    "__Assumptions:__\n",
    "- Emulation is made fast by bypassing image generation; we model each object as a mixture of Gaussians and the point-spread function (PSF) as a circular Gaussian so that we can _analytically_ compute the first and second moments required to populate the Source Catalog. \n",
    "- We also assume a fairly good deblender with a fixed deblending scale of 0.5\"--chosen because it roughly corresponds to the full-width half maximum (FWHM) of the best LSST PSF. All sources located within the deblending scale of an object for a given visit will contribute to the moments of that object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Choosing the OpSim fields\n",
    "The OpSim database is organized in terms of 5292 viewing fields generated from a tesselation of the sky ([OpSim catalog schema documentation](https://www.lsst.org/scientists/simulations/opsim/summary-table-column-descriptions-v335)). The observing schedule and conditions are the same within each field so, for computational efficiency, CosmoDC2Realizer first identifies the set of fields over which to realize the comprising objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Session',), (u'Config',), (u'Field',), (u'ObsHistory',), (u'Proposal',), (u'SeqHistory',), (u'SlewHistory',), (u'SlewActivities',), (u'SlewState',), (u'SlewMaxSpeeds',), (u'TimeHistory',), (u'ObsHistory_Proposal',), (u'Cloud',), (u'Seeing',), (u'Log',), (u'Config_File',), (u'Proposal_Field',), (u'SeqHistory_ObsHistory',), (u'MissedHistory',), (u'SeqHistory_MissedHistory',), (u'Summary',)]\n"
     ]
    }
   ],
   "source": [
    "# Read in the minion_1016 opsim database\n",
    "opsim_v3 = os.path.join('..', 'data', 'minion_1016_sqlite.db')\n",
    "conn = sqlite3.connect(opsim_v3)\n",
    "\n",
    "# See which tables the db file has\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are primarily interested in two tables of the `minion_1016` database: `ObsHistory` containing the observation conditions and `Field` containing the field positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.1 s, sys: 2.2 s, total: 26.3 s\n",
      "Wall time: 26.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time # ~ 25s\n",
    "# Save the tables ObsHistory and Field as Pandas DataFrames\n",
    "obs_history = pd.read_sql(sql='SELECT * from ObsHistory', con=conn)\n",
    "field = pd.read_sql(sql='SELECT * from Field', con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For speed considerations, we will only work with galaxies in `cosmoDC2_v1.0_9556`, a version of the extragalactic catalog restricted to one healpixel. This healpixel, it turns out, roughly coincides with the OpSim field with ID 1188 so we pre-save a subset of the `ObsHistory` table with `field_id=1188` and columns we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'obsHistID', u'Session_sessionID', u'filter', u'expDate', u'expMJD',\n",
       "       u'night', u'visitTime', u'visitExpTime', u'finRank', u'finSeeing',\n",
       "       u'transparency', u'airmass', u'vSkyBright', u'filtSkyBrightness',\n",
       "       u'rotSkyPos', u'lst', u'altitude', u'azimuth', u'dist2Moon',\n",
       "       u'solarElong', u'moonRA', u'moonDec', u'moonAlt', u'moonAZ',\n",
       "       u'moonPhase', u'sunAlt', u'sunAZ', u'phaseAngle', u'rScatter',\n",
       "       u'mieScatter', u'moonIllum', u'moonBright', u'darkBright', u'rawSeeing',\n",
       "       u'wind', u'humidity', u'fiveSigmaDepth', u'ditheredRA', u'ditheredDec',\n",
       "       u'Field_fieldID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_history.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obs_history = os.path.join('..', 'data', 'obs_history_1188.csv')\n",
    "save_field = os.path.join('..', 'data', 'field.csv')\n",
    "\n",
    "obs_history_1188 = obs_history.loc[obs_history['Field_fieldID']==field_id]\n",
    "\n",
    "obs_keep_cols = ['obsHistID', 'Field_fieldID', 'expMJD', 'finSeeing', 'fiveSigmaDepth', 'filtSkyBrightness', 'filter',]\n",
    "obs_history_1188 = obs_history_1188[obs_keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "field.loc[(np.abs(field['fieldRA'] - 56.25) < 2) & (np.abs(field['fieldDec'] - (-34.24)) < 2)]\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_history_1188.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_history_1188.to_csv(save_obs_history, index=False)\n",
    "field.to_csv(save_field, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `field` table, we can get the central RA and dec of our field. All fields have a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting galaxies\n",
    "We query the extragalactic catalog for objects that lie in this field. As mentioned earlier, we load `cosmoDC2_v1.0_9556` rather than the full cosmoDC2 catalog in this notebook for fast demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "catalog = GCRCatalogs.load_catalog('cosmoDC2_v1.0_9556')\n",
    "#catalog = GCRCatalogs.load_catalog('cosmoDC2_v1.0_image')\n",
    "# 'cosmoDC2_v1.0_image' takes ~14 sec\n",
    "quantities = ['galaxy_id', 'ra_true', 'dec_true', 'redshift_true', \n",
    "              'size_bulge_true', 'size_minor_bulge_true', 'sersic_bulge', 'ellipticity_1_bulge_true',\n",
    "              'ellipticity_2_bulge_true', 'ellipticity_bulge_true',\n",
    "              'size_disk_true', 'size_minor_disk_true', 'sersic_disk', 'ellipticity_1_disk_true',\n",
    "              'ellipticity_2_disk_true', 'ellipticity_disk_true',\n",
    "              #'ellipticity_1_true', 'ellipticity_2_true',\n",
    "              #'position_angle_true', 'ellipticity_true',\n",
    "              #'size_true', 'size_minor_true', 'sersic',\n",
    "              'bulge_to_total_ratio_i',\n",
    "              'mag_true_u_lsst',\n",
    "              'mag_true_g_lsst',\n",
    "              'mag_true_r_lsst',\n",
    "              'mag_true_i_lsst',\n",
    "              'mag_true_z_lsst',\n",
    "              'mag_true_Y_lsst',\n",
    "              'is_central', 'halo_mass',]\n",
    "\n",
    "cuts = [# A loose magnitude cut\n",
    "        #GCRQuery('mag_true_g_lsst < 27'), \n",
    "        # Query halo masses likely to host an AGN\n",
    "        GCRQuery('halo_mass > 1.e13'),\n",
    "        # Query sources belonging to Field 1188\n",
    "        GCRQuery('abs(ra_true - %f) < %f' %(field_ra, field_radius)),\n",
    "        GCRQuery('abs(dec_true - %f) < %f' %(field_dec, field_radius)),]\n",
    "# Add filters as necessary!\n",
    "galaxies = catalog.get_quantities(quantities, filters=cuts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a small subset of 1000 galaxies to realize. These galaxies will be at the center of our viewing window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_galaxy_df.to_csv('small_galaxy_df.csv', index='galaxy_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Getting line-of-sight neighbors\n",
    "For each extended galaxy source, any other galaxy or point source (unlensed AGN or star) that lie within its blending scale will be its line-of-sight neighbor. Galaxy neighbors will simply be taken from the extragalactic catalog, which we've already fetched. Point-source neighbors will be taken from the truth catalog as below.\n",
    "\n",
    "### Getting the neighbors (unlensed AGNs and stars) from the truth catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth_catalog = GCRCatalogs.load_catalog('dc2_truth_run1.1_static')\n",
    "truth_catalog = GCRCatalogs.load_catalog('dc2_truth_run1.1', {'md5': None})\n",
    "\n",
    "truth_catalog_columns = ['object_id', 'ra', 'dec', 'star', 'agn', 'sprinkled', 'healpix_2048',\n",
    "                        'u', 'g', 'r', 'i', 'z', 'y',]\n",
    "\n",
    "ra_min, ra_max = field_ra - field_radius, field_ra + field_radius\n",
    "dec_min, dec_max = field_dec - field_radius, field_dec + field_radius\n",
    "\n",
    "field_ra_rad = np.radians(field_ra)\n",
    "field_dec_rad = np.radians(field_dec)\n",
    "\n",
    "center_vec = np.array([np.cos(field_dec_rad)*np.cos(field_ra_rad),\n",
    "                       np.cos(field_dec_rad)*np.sin(field_ra_rad),\n",
    "                       np.sin(field_dec_rad)])\n",
    "\n",
    "list_of_healpix = healpy.query_disc(2048, center_vec, np.radians(radius), nest=True, inclusive=True)\n",
    "\n",
    "def filter_on_healpix(hp):\n",
    "    return np.array([hh in list_of_healpix for hh in hp])\n",
    "\n",
    "coord_filters = [\n",
    "    'ra >= {}'.format(ra_min),\n",
    "    'ra < {}'.format(ra_max),\n",
    "    'dec >= {}'.format(dec_min),\n",
    "    'dec < {}'.format(dec_max),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# around 15s on Jupyter-dev\n",
    "neighbors = truth_catalog.get_quantities(truth_catalog_columns,\n",
    "                                            native_filters=['(star==1) or (agn==1)',\n",
    "                                                            'sprinkled==0',\n",
    "                                                            'healpix_2048<=%d' % list_of_healpix.max(),\n",
    "                                                            'healpix_2048>=%d' % list_of_healpix.min()],\n",
    "                                            filters=[(filter_on_healpix, 'healpix_2048')]+coord_filters)  \n",
    "neighbors = pd.DataFrame(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwp/.local/lib/python2.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/jwp/.local/lib/python2.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/jwp/.local/lib/python2.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/jwp/.local/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/jwp/.local/lib/python2.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/jwp/.local/lib/python2.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/jwp/.local/lib/python2.7/site-packages/ipykernel_launcher.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/jwp/.local/lib/python2.7/site-packages/ipykernel_launcher.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/jwp/.local/lib/python2.7/site-packages/ipykernel_launcher.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# delete later\n",
    "data_dir = os.path.join('..', 'data')\n",
    "obs_history = pd.read_csv(os.path.join(data_dir, 'obs_history_1188.csv'))\n",
    "field = pd.read_csv(os.path.join(data_dir, 'field.csv'))\n",
    "galaxies = pd.read_csv(os.path.join(data_dir, 'small_galaxy_df.csv'))\n",
    "neighbors = pd.read_csv(os.path.join(data_dir, 'neighbors.csv'), index_col='object_id')\n",
    "#TODO index=False when saving galaxy df\n",
    "\n",
    "source_columns = ['sourceId', 'ccdVisitId', 'objectId',\n",
    "                  'ra', 'dec', #'radec', #'radecCov',\n",
    "                 'apFlux', 'apFluxErr',\n",
    "                 'sky', #'skyErr',\n",
    "                 'Ixx', 'Iyy', 'Ixy', #'Icov',\n",
    "                 'IxxPSF', #'IyyPSF', 'IxyPSF',\n",
    "                 #'extendedness',\n",
    "                 ]\n",
    "#source = pd.DataFrame(columns=source_columns)\n",
    "\n",
    "deblending_scale = 0.5*100.0 # arcsec\n",
    "# Information about the field we will work with\n",
    "field_ids = [1188,]\n",
    "field_radius = utils.deg_to_arcsec(0.5*3.5) # arcsec\n",
    "field_id = 1188\n",
    "#field_ra = 55.127186 #deg\n",
    "#field_dec = -33.448002 #deg\n",
    "\n",
    "# Pre-save tables field and obs_history as Pandas DataFrame\n",
    "# Pre-save subset of extragalactic catalog corresponding to fields in field_ids as Pandas DataFrame\n",
    "# Pre-save subset of truth catalog corresponding to fields in fields_ids as Pandas DataFrame\n",
    "\n",
    "# TODO: make sure galaxies has galaxy_id\n",
    "galaxies[['ra_true', 'dec_true']] = utils.deg_to_arcsec(galaxies[['ra_true', 'dec_true']])\n",
    "neighbors[['ra', 'dec']] = utils.deg_to_arcsec(neighbors[['ra', 'dec']])\n",
    "field[['fieldRA', 'fieldDec']] = utils.deg_to_arcsec(field[['fieldRA', 'fieldDec']])\n",
    "\n",
    "moments = ['ra', 'dec', 'Ixx', 'Iyy', 'Ixy', 'apFlux']\n",
    "filters = list('ugrizy')\n",
    "moment_cols = [mom + '_' + bp for mom, bp in product(moments, filters)]\n",
    "metadata_cols = ['sourceId', 'objectId', 'num_gal_neighbors', 'num_point_neighbors']\n",
    "\n",
    "source_in_fields = []\n",
    "\n",
    "for field_id in field_ids:\n",
    "    # Query obs_history for the field of interest\n",
    "    obs_history_in_field = obs_history.loc[obs_history['Field_fieldID']==field_id]\n",
    "    num_observations = obs_history_in_field.shape[0]\n",
    "    \n",
    "    # Find field center for field id by querying the field table of OpSim db\n",
    "    field_info = field.loc[field['fieldID']==field_id]\n",
    "    field_ra = field_info['fieldRA'].item()\n",
    "    field_dec = field_info['fieldDec'].item()\n",
    "    \n",
    "    # Query extragalactic catalog for galaxies within field\n",
    "    gal_positions = np.c_[galaxies[['ra_true' ,'dec_true']].values]\n",
    "    gal_tree = spatial.cKDTree(gal_positions)\n",
    "    galaxies_in_field_idx = gal_tree.query_ball_point(x=[field_ra, field_dec], r=field_radius, p=2)\n",
    "    galaxies_in_field = galaxies.iloc[galaxies_in_field_idx]\n",
    "    num_galaxies = len(galaxies_in_field_idx)\n",
    "    print(num_galaxies)\n",
    "    \n",
    "    # Query truth catalog for stars/AGNs within field\n",
    "    point_positions = np.c_[neighbors[['ra', 'dec']].values]\n",
    "    point_tree = spatial.cKDTree(point_positions)\n",
    "    points_in_field_idx = point_tree.query_ball_point(x=[field_ra, field_dec], r=field_radius, p=2)\n",
    "    points_in_field = neighbors.iloc[points_in_field_idx]\n",
    "    \n",
    "    # Initialize two DataFrames to populate before joining with obs_history_in_field\n",
    "    moments_pre_observed = pd.DataFrame(columns=moment_cols)\n",
    "    metadata_pre_observed = pd.DataFrame(columns=metadata_cols)\n",
    "    \n",
    "    for gal_idx in range(1): #range(num_galaxies):\n",
    "        # Initialize dictionaries to be propagated for this blended system\n",
    "        moments_row = {}\n",
    "        metadata_row = {}\n",
    "        \n",
    "        # Central galaxy\n",
    "        central_gal = galaxies_in_field.iloc[gal_idx]\n",
    "        ra_center, dec_center = central_gal['ra_true'], central_gal['dec_true'] # pos of central galaxy\n",
    "        metadata_row['sourceId'] = gal_idx\n",
    "        metadata_row['objectId'] = central_gal['galaxy_id']\n",
    "        \n",
    "        ##########################\n",
    "        # Find blended neighbors #\n",
    "        ##########################\n",
    "        # Galaxy neighbors (extended)\n",
    "        gal_positions_field = np.c_[galaxies_in_field[['ra_true' ,'dec_true']].values]\n",
    "        gal_tree_field = spatial.cKDTree(gal_positions_field)\n",
    "        gal_idx = gal_tree_field.query_ball_point(x=[ra_center, dec_center], r=deblending_scale, p=2)\n",
    "        num_gal_neighbors = len(gal_idx) - 1 # subtract central galaxy itself\n",
    "        metadata_row['num_gal_neighbors'] = num_gal_neighbors\n",
    "        all_gal = galaxies_in_field.iloc[gal_idx] # includes the central galaxy, not just neighbors\n",
    "        # Stars/AGN neighbors (point)\n",
    "        point_positions_field = np.c_[points_in_field[['ra', 'dec']].values]\n",
    "        point_tree_field = spatial.cKDTree(point_positions_field)\n",
    "        point_neighbors_idx = point_tree_field.query_ball_point(x=[ra_center, dec_center], r=deblending_scale, p=2)\n",
    "        num_point_neighbors = len(point_neighbors_idx)\n",
    "        metadata_row['num_point_neighbors'] = num_point_neighbors\n",
    "        point = points_in_field.iloc[point_neighbors_idx]\n",
    "        print(num_point_neighbors)\n",
    "        \n",
    "        # Separate galaxy catalog into bulge and disk\n",
    "        bulge, disk, all_gal = separate_bulge_disk(all_gal)\n",
    "        \n",
    "        ###############\n",
    "        # Flux ratios #\n",
    "        ###############\n",
    "        for bp in 'ugrizy':\n",
    "            # Convert mag to flux in point_neighbors\n",
    "            point['flux_%s' %bp] = utils.mag_to_flux(point[bp].values, to_unit='nMgy')\n",
    "            # Store total flux of blended system\n",
    "            moments_row['apFlux_%s' %bp] = all_gal['flux_%s' %bp].sum() +  point['flux_%s' %bp].sum()\n",
    "            # Divide all fluxes by total blended flux, to get flux ratios\n",
    "            total_blended_flux = moments_row['apFlux_%s' %bp] \n",
    "            all_gal['flux_%s' %bp] /= total_blended_flux\n",
    "            bulge['flux_%s' %bp] /= total_blended_flux\n",
    "            disk['flux_%s' %bp] /= total_blended_flux\n",
    "            point['flux_%s' %bp] /= total_blended_flux\n",
    "        \n",
    "        ###############\n",
    "        # 1st moments #\n",
    "        ###############\n",
    "        for bp in 'ugrizy':\n",
    "            # Calculate contribution to 1st moment in each band and gal/point of blended system\n",
    "            all_gal['Ix_contrib_%s' %bp] = all_gal['ra_true']*all_gal['flux_%s' %bp]\n",
    "            all_gal['Iy_contrib_%s' %bp] = all_gal['dec_true']*all_gal['flux_%s' %bp]\n",
    "            point['Ix_contrib_%s' %bp] = point['ra']*point['flux_%s' %bp]\n",
    "            point['Iy_contrib_%s' %bp] = point['dec']*point['flux_%s' %bp]\n",
    "            # Sum to get 1st moment of blended system\n",
    "            moments_row['ra_%s' %bp] = all_gal['Ix_contrib_%s' %bp].sum() + point['Ix_contrib_%s' %bp].sum()\n",
    "            moments_row['dec_%s' %bp] = all_gal['Iy_contrib_%s' %bp].sum() + point['Iy_contrib_%s' %bp].sum()\n",
    "        \n",
    "        ###############\n",
    "        # 2nd moments #\n",
    "        ###############\n",
    "        # Deconstruct bulge/disk into MoG\n",
    "        bulge_mog = sersic_to_mog(sersic_df=bulge, bulge_or_disk='bulge')\n",
    "        disk_mog = sersic_to_mog(sersic_df=disk, bulge_or_disk='disk')\n",
    "        # Calculate contribution to 1st moment\n",
    "        # ... in each band and Gaussian of blended system\n",
    "        bulge_mog = calculate_2nd_moment_contrib_mog(mog_df=bulge_mog, moments_dict=moments_row)\n",
    "        disk_mog = calculate_2nd_moment_contrib_mog(mog_df=disk_mog, moments_dict=moments_row)\n",
    "        # ... in each band and point of blended system\n",
    "        point = calculate_2nd_moment_contrib_point(point_df=point, moments_dict=moments_row)\n",
    "        # Sum to get 2nd moment of blended system\n",
    "        for bp in 'ugrizy':\n",
    "            for mom in ['Ixx', 'Iyy', 'Ixy']:\n",
    "                final_mom = bulge_mog['%s_contrib_%s' %(mom, bp)].sum() \n",
    "                final_mom += disk_mog['%s_contrib_%s' %(mom, bp)].sum() \n",
    "                final_mom += point['%s_contrib_%s' %(mom, bp)].sum() \n",
    "                moments_row['%s_%s' %(mom, bp)] = final_mom\n",
    "    \n",
    "        moments_pre_observed = moments_pre_observed.append(moments_row, ignore_index=True)\n",
    "        metadata_pre_observed = metadata_pre_observed.append(metadata_row, ignore_index=True)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'index', u'size_minor_true', u'bulge_to_total_ratio_i',\n",
       "       u'ellipticity_1_true', u'ellipticity_2_true', u'ellipticity_true',\n",
       "       u'size_true', u'sersic', u'flux_u', u'flux_g', u'flux_r', u'flux_i',\n",
       "       u'flux_z', u'flux_y', u'ra_true', u'dec_true', u'size_circular',\n",
       "       u'gauss_norm', u'stdev', u'weight', u'Ixx_contrib_u', u'Iyy_contrib_u',\n",
       "       u'Ixy_contrib_u', u'Ixx_contrib_g', u'Iyy_contrib_g', u'Ixy_contrib_g',\n",
       "       u'Ixx_contrib_r', u'Iyy_contrib_r', u'Ixy_contrib_r', u'Ixx_contrib_i',\n",
       "       u'Iyy_contrib_i', u'Ixy_contrib_i', u'Ixx_contrib_z', u'Iyy_contrib_z',\n",
       "       u'Ixy_contrib_z', u'Ixx_contrib_y', u'Iyy_contrib_y', u'Ixy_contrib_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bulge_mog.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ra_u</th>\n",
       "      <th>ra_g</th>\n",
       "      <th>ra_r</th>\n",
       "      <th>ra_i</th>\n",
       "      <th>ra_z</th>\n",
       "      <th>ra_y</th>\n",
       "      <th>dec_u</th>\n",
       "      <th>dec_g</th>\n",
       "      <th>dec_r</th>\n",
       "      <th>dec_i</th>\n",
       "      <th>dec_z</th>\n",
       "      <th>dec_y</th>\n",
       "      <th>Ixx_u</th>\n",
       "      <th>Ixx_g</th>\n",
       "      <th>Ixx_r</th>\n",
       "      <th>Ixx_i</th>\n",
       "      <th>Ixx_z</th>\n",
       "      <th>Ixx_y</th>\n",
       "      <th>Iyy_u</th>\n",
       "      <th>Iyy_g</th>\n",
       "      <th>Iyy_r</th>\n",
       "      <th>Iyy_i</th>\n",
       "      <th>Iyy_z</th>\n",
       "      <th>Iyy_y</th>\n",
       "      <th>Ixy_u</th>\n",
       "      <th>Ixy_g</th>\n",
       "      <th>Ixy_r</th>\n",
       "      <th>Ixy_i</th>\n",
       "      <th>Ixy_z</th>\n",
       "      <th>Ixy_y</th>\n",
       "      <th>apFlux_u</th>\n",
       "      <th>apFlux_g</th>\n",
       "      <th>apFlux_r</th>\n",
       "      <th>apFlux_i</th>\n",
       "      <th>apFlux_z</th>\n",
       "      <th>apFlux_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200482.468863</td>\n",
       "      <td>200482.478684</td>\n",
       "      <td>200482.48692</td>\n",
       "      <td>200482.491487</td>\n",
       "      <td>200482.491441</td>\n",
       "      <td>200482.493494</td>\n",
       "      <td>-126294.671992</td>\n",
       "      <td>-126294.638848</td>\n",
       "      <td>-126294.610891</td>\n",
       "      <td>-126294.596126</td>\n",
       "      <td>-126294.595327</td>\n",
       "      <td>-126294.587597</td>\n",
       "      <td>2.682322</td>\n",
       "      <td>2.486058</td>\n",
       "      <td>2.321107</td>\n",
       "      <td>2.230513</td>\n",
       "      <td>2.230216</td>\n",
       "      <td>2.188078</td>\n",
       "      <td>11.316441</td>\n",
       "      <td>10.320565</td>\n",
       "      <td>9.4797</td>\n",
       "      <td>9.031149</td>\n",
       "      <td>9.012038</td>\n",
       "      <td>8.782953</td>\n",
       "      <td>4.171484</td>\n",
       "      <td>3.827102</td>\n",
       "      <td>3.537695</td>\n",
       "      <td>3.377421</td>\n",
       "      <td>3.378493</td>\n",
       "      <td>3.305762</td>\n",
       "      <td>1.969478</td>\n",
       "      <td>9.309461</td>\n",
       "      <td>25.257668</td>\n",
       "      <td>38.895389</td>\n",
       "      <td>48.970699</td>\n",
       "      <td>58.498118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ra_u           ra_g          ra_r           ra_i           ra_z  \\\n",
       "0  200482.468863  200482.478684  200482.48692  200482.491487  200482.491441   \n",
       "\n",
       "            ra_y          dec_u          dec_g          dec_r          dec_i  \\\n",
       "0  200482.493494 -126294.671992 -126294.638848 -126294.610891 -126294.596126   \n",
       "\n",
       "           dec_z          dec_y     Ixx_u     Ixx_g     Ixx_r     Ixx_i  \\\n",
       "0 -126294.595327 -126294.587597  2.682322  2.486058  2.321107  2.230513   \n",
       "\n",
       "      Ixx_z     Ixx_y      Iyy_u      Iyy_g   Iyy_r     Iyy_i     Iyy_z  \\\n",
       "0  2.230216  2.188078  11.316441  10.320565  9.4797  9.031149  9.012038   \n",
       "\n",
       "      Iyy_y     Ixy_u     Ixy_g     Ixy_r     Ixy_i     Ixy_z     Ixy_y  \\\n",
       "0  8.782953  4.171484  3.827102  3.537695  3.377421  3.378493  3.305762   \n",
       "\n",
       "   apFlux_u  apFlux_g   apFlux_r   apFlux_i   apFlux_z   apFlux_y  \n",
       "0  1.969478  9.309461  25.257668  38.895389  48.970699  58.498118  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moments_pre_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = ['totalflux', 'Ix', 'Ixx', 'Iy', 'Iyy', 'Ixy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_bulge_disk(extragal_df):\n",
    "    # Rename for conciseness\n",
    "    df = extragal_df\n",
    "    # Add disk_to_total_ratio_i = 1.0 - bulge_to_total_ratio_i\n",
    "    df['disk_to_total_ratio'] = 1.0 - df['bulge_to_total_ratio_i'].values\n",
    "    # Make column names all lowercase for convenience\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    # Add flux column for each filter, disk/bulge flux\n",
    "    for bandpass in 'ugrizy':\n",
    "        df['flux_%s' %bandpass] = utils.mag_to_flux(df['mag_true_%s_lsst' %bandpass].values, to_unit='nMgy')\n",
    "        df['flux_%s_disk' %bandpass] = df['flux_%s' %bandpass].values*df['disk_to_total_ratio'].values\n",
    "        df['flux_%s_bulge' %bandpass] = df['flux_%s' %bandpass].values*df['bulge_to_total_ratio_i'].values\n",
    "    # Copy ra and dec to both disk and bulge DataFrames (not sure if necessary)\n",
    "    for component in ['disk', 'bulge']:\n",
    "        df['ra_true_%s' %component] = df['ra_true'].values\n",
    "        df['dec_true_%s' %component] = df['dec_true'].values\n",
    "    # Separate df into bulge-related and disk-related\n",
    "    bulge_df = df.filter(like='bulge', axis=1).copy()\n",
    "    disk_df = df.filter(like='disk', axis=1).copy()\n",
    "    # Make column schema the same across bulge and disk DataFrames (not sure if necessary)\n",
    "    bulge_df.columns = [col.strip().replace('_bulge', '') for col in bulge_df.columns]\n",
    "    disk_df.columns = [col.strip().replace('_disk', '') for col in disk_df.columns]\n",
    "    # Sersic size before shear transformation\n",
    "    bulge_df['size_circular'] = (bulge_df['size_minor_true']*bulge_df['size_true'])**0.5\n",
    "    disk_df['size_circular'] = (disk_df['size_minor_true']*disk_df['size_true'])**0.5\n",
    "    return bulge_df, disk_df, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sersic_to_mog(sersic_df, bulge_or_disk):\n",
    "    \n",
    "    if bulge_or_disk=='bulge':\n",
    "        # Mixture of gaussian parameters for de Vaucouleurs profile from HL13\n",
    "        weights = [0.00139, 0.00941, 0.04441, 0.16162, 0.48121, 1.20357, 2.54182, 4.46441, 6.22821, 6.15393]\n",
    "        stdevs = [0.00087, 0.00296, 0.00792, 0.01902, 0.04289, 0.09351, 0.20168, 0.44126, 1.01833, 2.74555]\n",
    "        mog_params = {'weight': weights, 'stdev': stdevs}\n",
    "        sersic_norm = gammaincinv(8, 0.5)\n",
    "        gauss_norm = 40320.0*np.pi*np.exp(sersic_norm)/sersic_norm**8.0\n",
    "    elif bulge_or_disk=='disk':\n",
    "        # Mixture of gaussian parameters for exponential profile from HL13\n",
    "        weights = [0.00077, 0.01017, 0.07313, 0.37188, 1.39727, 3.56054, 4.74340, 1.78732]\n",
    "        stdevs = [0.02393, 0.06490, 0.13580, 0.25096, 0.42942, 0.69672, 1.08879, 1.67294]\n",
    "        mog_params = {'weight': weights, 'stdev': stdevs}\n",
    "        sersic_norm = gammaincinv(2, 0.5) # for exponential\n",
    "        gauss_norm = 2.0*np.pi*np.exp(sersic_norm)/sersic_norm**2.0\n",
    "    else:\n",
    "        raise ValueError(\"Component is either bulge or disk.\")\n",
    "    \n",
    "    sersic_df['gauss_norm'] = gauss_norm\n",
    "    mog_params_df = pd.DataFrame.from_dict(mog_params)\n",
    "    # Join bulge_df and mog_params_df\n",
    "    sersic_df = sersic_df.reset_index()\n",
    "    sersic_df['key'] = 0\n",
    "    mog_params_df['key'] = 0\n",
    "    mog = sersic_df.merge(mog_params_df, how='left', on='key')\n",
    "    mog = mog.drop('key', 1)\n",
    "    \n",
    "    return mog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_2nd_moment_contrib_mog(mog_df, moments_dict):\n",
    "\n",
    "    # Calculate contribution to 2nd moment from each filter and Gaussian\n",
    "    for bp in 'ugrizy':\n",
    "        e1 = mog_df['ellipticity_1_true']\n",
    "        e2 = mog_df['ellipticity_2_true']\n",
    "        gauss_sigma = mog_df['size_circular']*mog_df['stdev']\n",
    "        gauss_weight = mog_df['weight']/mog_df['gauss_norm']\n",
    "        flux_ratio = mog_df['flux_%s' %bp]*gauss_weight\n",
    "        ra = mog_df['ra_true']\n",
    "        dec = mog_df['dec_true']\n",
    "        reference_Ix = moments_dict['ra_%s' %bp]\n",
    "        reference_Iy = moments_dict['dec_%s' %bp]\n",
    "        Ixx, Iyy, Ixy = get_second_moments(e1=e1, e2=e2, sigma=gauss_sigma)\n",
    "        mog_df['Ixx_contrib_%s' %bp] = flux_ratio*(Ixx + (ra - reference_Ix)**2.0)\n",
    "        mog_df['Iyy_contrib_%s' %bp] = flux_ratio*(Iyy + (dec - reference_Iy)**2.0)\n",
    "        mog_df['Ixy_contrib_%s' %bp] = flux_ratio*(Ixy + (ra - reference_Ix)*(dec - reference_Iy))\n",
    "    \n",
    "    return mog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_2nd_moment_contrib_point(point_df, moments_dict):\n",
    "\n",
    "    # Calculate contribution to 2nd moment from each filter and Gaussian\n",
    "    for bp in 'ugrizy':\n",
    "        flux_ratio = point_df['flux_%s' %bp]\n",
    "        ra = point_df['ra']\n",
    "        dec = point_df['dec']\n",
    "        reference_Ix = moments_dict['ra_%s' %bp]\n",
    "        reference_Iy = moments_dict['dec_%s' %bp]\n",
    "        point_df['Ixx_contrib_%s' %bp] = flux_ratio*((ra - reference_Ix)**2.0)\n",
    "        point_df['Iyy_contrib_%s' %bp] = flux_ratio*((dec - reference_Iy)**2.0)\n",
    "        point_df['Ixy_contrib_%s' %bp] = flux_ratio*((ra - reference_Ix)*(dec - reference_Iy))\n",
    "    \n",
    "    return point_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second_moments(e1, e2, sigma):\n",
    "    theta = 0.5*np.arctan(e2/e1)\n",
    "    e = (e1**2.0 + e2**2.0)**0.5\n",
    "    sqrt_q = ((1.0 - e)/(1.0 + e))**0.5\n",
    "    lam1 = sigma**2.0/sqrt_q\n",
    "    lam2 = sigma**2.0*sqrt_q\n",
    "    cos = np.cos(theta)\n",
    "    sin = np.sin(theta)\n",
    "    Ixx = lam1*cos**2.0 + lam2*sin**2.0\n",
    "    Iyy = lam1*sin**2.0 + lam2*cos**2.0\n",
    "    Ixy = (lam1 - lam2)*cos*sin\n",
    "    return Ixx, Iyy, Ixy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-eb1668050ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marctan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "np.arctan(0.0/0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-bccee2bf71c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marctan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'ugrizy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'b4' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(b4, b1)\n",
    "\n",
    "for bp in 'ugrizy':\n",
    "    e1 = obj['ellipticity_1_true']\n",
    "    e2 = obj['ellipticity_2_true']\n",
    "    gauss_sigma = obj['size_circular']*obj['stdev']\n",
    "    gauss_weight = obj['weight']/gauss_norm\n",
    "    flux_ratio = obj['flux_%s' %bp]*gauss_weight\n",
    "    ra = obj['ra_true']\n",
    "    dec = obj['dec_true']\n",
    "    Ix = derived_properties['Ix_%s' %bp]\n",
    "    Iy = derived_properties['Iy_%s' %bp]\n",
    "    Ixx, Iyy, Ixy = get_second_moments(e1=e1, e2=e2, sigma=gauss_sigma)\n",
    "    obj['Ixx_contrib_%s' %bp] = flux_ratio*(Ixx + (ra - Ix)**2.0)\n",
    "    obj['Iyy_contrib_%s' %bp] = flux_ratio*(Iyy + (dec - Iy)**2.0)\n",
    "    obj['Ixy_contrib_%s' %bp] = flux_ratio*(Ixy + (ra - Ix)*(dec - Iy))\n",
    "    derived_properties['Ixx_%s' %bp] = obj['Ixx_contrib_%s' %bp].sum()\n",
    "    derived_properties['Iyy_%s' %bp] = obj['Iyy_contrib_%s' %bp].sum()\n",
    "    derived_properties['Ixy_%s' %bp] = obj['Ixy_contrib_%s' %bp].sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {'a': 1, 'b': 2, 'c': 3}\n",
    "#mom = {'d': 4, 'e': 5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_observed = pd.DataFrame(columns=derived_properties.keys())\n",
    "\n",
    "before_observed = before_observed.append(derived_properties, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before_observed.columns = before_observed.columns.str.split('_', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before_observed = before_observed.reorder_levels([1,0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before_observed = before_observed.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "before_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_history_in_field = obs_history.loc[obs_history['Field_fieldID']==field_id][['filter']]\n",
    "#obs_history_in_field.columns = pd.MultiIndex.from_product([['obs'], obs_history_in_field.columns])\n",
    "obs_history_in_field = obs_history_in_field.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_observed['key'] = 0\n",
    "obs_history_in_field['key'] = 0\n",
    "obj = before_observed.merge(obs_history_in_field, how='left', on='key')\n",
    "obj = obj.drop('key', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obj.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
