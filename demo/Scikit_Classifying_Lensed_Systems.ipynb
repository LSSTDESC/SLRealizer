{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cornerplots of various features for lensed system\n",
    "### SDSS vs OM10 (realized by Galsim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The OM10 mock lensed quasar catalog qso_mock.fits contains a list of LSST-like samples. Using the OM10 mock catalog and observation history data, we can generate a toy catalog for SLRealizer. Using the toy catalog, we can null-deblend the catalog and generate the cornerplot to easily compare different features. We use Galsim to null-deblend and realize the catalog. Then, we compared the OM10 features with SDSS features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from astropy.table import Table, hstack\n",
    "import astropy.io.fits as pyfits\n",
    "import sys, os\n",
    "import desc.slrealizer\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines below enable the jupyter notebook to display inline plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "matplotlib.use('TkAgg')\n",
    "matplotlib.rc('text', usetex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we initialize SLRealizer constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realizer = desc.slrealizer.SLRealizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make the feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the cornerplot that we drew of SDSS and OM10, we make a new catalog that has only useful features. We choose six features:\n",
    "\n",
    "- Difference in sizes between u and z bands\n",
    "- Difference in ellipticities between u and z bands (e)\n",
    "- Difference in rotation angles of the systems between u and z bands (ϕ)\n",
    "- Difference in angles between centroid positions and galactic shears (ω) \n",
    "- Difference in magnitudes between u and z bands\n",
    "- Difference in positions of the centroid between u and z bands (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do so, we first load the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import desc.slrealizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we read in the object_table and the sdss_table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_table = pd.read_csv('../data/object_catalog_galsim_noise_perfect.csv')\n",
    "sdss_table = pd.read_csv('../data/sdss_object.csv').head(len(object_table)) # make sure that we have the same number of 0s and 1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we calculate each entrees of six useful features. First, we do that for object_table(om10) and save into `truth_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([])\n",
    "u_e = object_table['u_e']\n",
    "z_e = object_table['z_e']\n",
    "u_phi = object_table['u_phi']\n",
    "z_phi = object_table['z_phi']\n",
    "delta_e = u_e - z_e\n",
    "delta_phi = (object_table['u_phi']-object_table['z_phi'])\n",
    "u = desc.slrealizer.return_zeropoint()-2.5*np.log10(object_table['u_flux'])\n",
    "z = desc.slrealizer.return_zeropoint()-2.5*np.log10(object_table['z_flux'])\n",
    "u_z = u - z\n",
    "u_x = object_table['u_x'] - object_table['r_x']\n",
    "u_y = object_table['u_y'] - object_table['r_y']\n",
    "u_e1 = object_table['u_e1']\n",
    "u_e2 = object_table['u_e2']\n",
    "u_ex = u_x* (u_e1*np.cos(u_phi) - u_e2*np.sin(u_phi))\n",
    "u_ey = u_y* (u_e1*np.sin(u_phi) + u_e2*np.cos(u_phi))\n",
    "z_x = object_table['z_x'] - object_table['r_x']\n",
    "z_y = object_table['z_y'] - object_table['r_y']\n",
    "z_e1 = object_table['z_e1']\n",
    "z_e2 = object_table['z_e2']\n",
    "z_ex = z_x * (z_e1*np.cos(z_phi) - z_e2*np.sin(z_phi))\n",
    "z_ey = z_y * (z_e1*np.cos(z_phi) - z_e2*np.sin(z_phi))\n",
    "pos_mod_u = np.sqrt(u_x*u_x + u_y*u_y)\n",
    "pos_mod_z = np.sqrt(z_x*z_x + z_y*z_y)\n",
    "delta_x = np.sqrt((u_x - z_x) * (u_x - z_x) + (u_y - z_y) * (u_y - z_y))\n",
    "delta_size = object_table['u_size']-object_table['z_size']\n",
    "\n",
    "u_omega = (u_ex+u_ey)/(u_e*pos_mod_u)\n",
    "z_omega = (z_ex+z_ey)/(z_e*pos_mod_z)\n",
    "\n",
    "diff_x = u_x - z_x\n",
    "diff_y = u_y - z_y\n",
    "pos_mod_diff = np.sqrt(diff_x * diff_x + diff_y * diff_y)\n",
    "\n",
    "omega_u_num = u_x*u_e*np.cos(2*u_phi) + u_x*u_e*np.sqrt(2)/2*np.sin(2*u_phi) + np.sqrt(2)/2 * u_y * u_e * np.sin(2*u_phi)\n",
    "omega_u_den = pos_mod_u * u_e *10\n",
    "omag_u = omega_u_num / omega_u_den\n",
    "\n",
    "omega_z_num = z_x*z_e*np.cos(2*z_phi) + z_x*z_e*np.sqrt(2)/2*np.sin(2*z_phi) + np.sqrt(2)/2 *z_y * z_e * np.sin(2*z_phi)\n",
    "omega_z_den = pos_mod_z * z_e * 10\n",
    "omag_z = omega_z_num / omega_z_den\n",
    "\n",
    "delta_omega = omag_u-omag_z\n",
    "\n",
    "delta_phi = delta_phi*57.2958\n",
    "\n",
    "truth = [1] * len(delta_omega)\n",
    "\n",
    "features = np.append(features, truth)\n",
    "features = np.append(features, delta_e)\n",
    "features = np.append(features, delta_phi)\n",
    "features = np.append(features, u_z)\n",
    "features = np.append(features, delta_x)\n",
    "features = np.append(features, delta_size)\n",
    "features = np.append(features, delta_omega)\n",
    "features = features.reshape(7, len(u_x)).transpose()\n",
    "data = pd.DataFrame(features, columns=['truth', 'delta_e', 'delta_phi', 'u_z', 'delta_x', 'delta_size', 'delta_omega'])\n",
    "data.to_csv('../data/truth_data.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for sdss_table, saving into `false_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([])\n",
    "u_e = sdss_table['u_e']\n",
    "z_e = sdss_table['z_e']\n",
    "u_phi = sdss_table['u_phi']\n",
    "z_phi = sdss_table['z_phi']\n",
    "delta_e = u_e - z_e\n",
    "delta_phi = (sdss_table['u_phi']-sdss_table['z_phi'])\n",
    "u = desc.slrealizer.return_zeropoint()-2.5*np.log10(sdss_table['u_flux'])\n",
    "z = desc.slrealizer.return_zeropoint()-2.5*np.log10(sdss_table['z_flux'])\n",
    "u_z = u - z\n",
    "u_x = sdss_table['u_x'] - sdss_table['r_x']\n",
    "u_y = sdss_table['u_y'] - sdss_table['r_y']\n",
    "u_e1 = sdss_table['u_e1']\n",
    "u_e2 = sdss_table['u_e2']\n",
    "u_ex = u_x* (u_e1*np.cos(u_phi) - u_e2*np.sin(u_phi))\n",
    "u_ey = u_y* (u_e1*np.sin(u_phi) + u_e2*np.cos(u_phi))\n",
    "z_x = sdss_table['z_x'] - sdss_table['r_x']\n",
    "z_y = sdss_table['z_y'] - sdss_table['r_y']\n",
    "z_e1 = sdss_table['z_e1']\n",
    "z_e2 = sdss_table['z_e2']\n",
    "z_ex = z_x * (z_e1*np.cos(z_phi) - z_e2*np.sin(z_phi))\n",
    "z_ey = z_y * (z_e1*np.cos(z_phi) - z_e2*np.sin(z_phi))\n",
    "pos_mod_u = np.sqrt(u_x*u_x + u_y*u_y)\n",
    "pos_mod_z = np.sqrt(z_x*z_x + z_y*z_y)\n",
    "delta_x = np.sqrt((u_x - z_x) * (u_x - z_x) + (u_y - z_y) * (u_y - z_y))\n",
    "delta_size = sdss_table['u_size']-sdss_table['z_size']\n",
    "\n",
    "u_omega = (u_ex+u_ey)/(u_e*pos_mod_u)\n",
    "z_omega = (z_ex+z_ey)/(z_e*pos_mod_z)\n",
    "\n",
    "diff_x = u_x - z_x\n",
    "diff_y = u_y - z_y\n",
    "pos_mod_diff = np.sqrt(diff_x * diff_x + diff_y * diff_y)\n",
    "\n",
    "omega_u_num = u_x*u_e*np.cos(2*u_phi) + u_x*u_e*np.sqrt(2)/2*np.sin(2*u_phi) + np.sqrt(2)/2 * u_y * u_e * np.sin(2*u_phi)\n",
    "omega_u_den = pos_mod_u * u_e *10\n",
    "omag_u = omega_u_num / omega_u_den\n",
    "\n",
    "omega_z_num = z_x*z_e*np.cos(2*z_phi) + z_x*z_e*np.sqrt(2)/2*np.sin(2*z_phi) + np.sqrt(2)/2 *z_y * z_e * np.sin(2*z_phi)\n",
    "omega_z_den = pos_mod_z * z_e * 10\n",
    "omag_z = omega_z_num / omega_z_den\n",
    "\n",
    "delta_omega = omag_u-omag_z\n",
    "\n",
    "delta_phi = delta_phi*57.2958\n",
    "\n",
    "truth = [0] * len(delta_omega)\n",
    "\n",
    "features = np.append(features, truth)\n",
    "features = np.append(features, delta_e)\n",
    "features = np.append(features, delta_phi)\n",
    "features = np.append(features, u_z)\n",
    "features = np.append(features, delta_x)\n",
    "features = np.append(features, delta_size)\n",
    "features = np.append(features, delta_omega)\n",
    "features = features.reshape(7, len(u_x)).transpose()\n",
    "sdss_data = pd.DataFrame(features, columns=['truth', 'delta_e', 'delta_phi', 'u_z', 'delta_x', 'delta_size', 'delta_omega'])\n",
    "sdss_data.to_csv('../data/false_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we merged the truth(om10) and the false(sdss) to one catalog, saving it into `training_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_merged =pd.concat([data, sdss_data], axis=0)\n",
    "df_col_merged = df_col_merged.sample(frac=1)\n",
    "df_col_merged.to_csv('../data/training_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning + Precision Recall Curve for various methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going two use three different algorithms : linearSVC, K-neighbors, and Random Forest. For the K-neighbors and Random Forest, we are going to change the number of neighbors and leaves. Then, we will see which classifier has the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do so, we import the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we divide training set and the test set within the whole data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_merged = df_col_merged.as_matrix()\n",
    "y = df_col_merged[:,0]\n",
    "last_col_index = len(df_col_merged[0])\n",
    "X = df_col_merged[:,1: last_col_index]\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, while training the Machine Learning algorithms, we also produce the precision-recall curve for each method so that we can compare the performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# linearsvc\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_score = clf.decision_function(X_test)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "plt.plot(recall, precision, label='Linear SVC', color='red')\n",
    "\n",
    "# kneighbors n=3\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train) \n",
    "y_score = neigh.predict_proba(X_test)[:,1]\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "plt.plot(recall, precision, label='NearestNeighbor N=3', color='orange')\n",
    "\n",
    "# kneighbors n=5\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train, y_train) \n",
    "y_score = neigh.predict_proba(X_test)[:,1]\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "plt.plot(recall, precision, label='NearestNeighbor N=5', color='green')\n",
    "\n",
    "# Random Forest N = 3\n",
    "clf = RandomForestClassifier(n_estimators=3)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_score = clf.predict_proba(X_test)[:,1]\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "plt.plot(recall, precision, label='Random Forest N=3', color='blue')\n",
    "\n",
    "# Random Forest N = 5\n",
    "clf = RandomForestClassifier(n_estimators=5)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_score = clf.predict_proba(X_test)[:,1]\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "plt.plot(recall, precision, label='Random Forest N=5', color='purple')\n",
    "\n",
    "# Random Forest N = 10\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_score = clf.predict_proba(X_test)[:,1]\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "plt.plot(recall, precision, label='Random Forest N=10', color='pink')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.title('Precision Recall Curve for various methods')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve for various methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going two use three different algorithms : linearSVC, K-neighbors, and Random Forest. For the K-neighbors and Random Forest, we are going to change the number of neighbors and leaves. Then, we will see which classifier has the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# linearsvc\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_score = clf.decision_function(X_test)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, y_score)\n",
    "plt.plot(fpr, tpr, color='red', label='Linear SVC ROC curve')\n",
    "\n",
    "# kneighbors n=3\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh = neigh.fit(X_train, y_train) \n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, neigh.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='yellow', label='Nearest Neighber N=3 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "# kneighbors n=5\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh = neigh.fit(X_train, y_train) \n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, neigh.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='#bad64d', label='Nearest Neighber N=5 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "# Random Forest N = 3\n",
    "clf = RandomForestClassifier(n_estimators=3, max_features=None)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='#43c6b7', label='RF N=3 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "\n",
    "# Random Forest N = 3\n",
    "clf = RandomForestClassifier(n_estimators=5, max_features=None)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='#2b84ad', label='RF N=5 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "# Random Forest N = 5\n",
    "clf = RandomForestClassifier(n_estimators=10, max_features=None)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='#8138a0', label='RF N=5 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "# Random Forest N = 10\n",
    "clf = RandomForestClassifier(n_estimators=15, max_features=None)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='pink', label='RF N=15 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20, max_features=None)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='#cc5d94', label='RF N=20 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=5000, max_features=None)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='#d63384', label='RF N=5000 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title('ROC for various methods')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a little hard to see where the turn-off points are, so let's concentrate on the top left corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linearsvc\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_score = clf.decision_function(X_test)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, y_score)\n",
    "plt.plot(fpr, tpr, color='red', label='Linear SVC ROC curve')\n",
    "\n",
    "# kneighbors n=3\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh = neigh.fit(X_train, y_train) \n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, neigh.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='yellow', label='Nearest Neighber N=3 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "# kneighbors n=5\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh = neigh.fit(X_train, y_train) \n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, neigh.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='#bad64d', label='Nearest Neighber N=5 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "# Random Forest N = 3\n",
    "clf = RandomForestClassifier(n_estimators=3, max_features=None)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='#43c6b7', label='RF N=3 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "\n",
    "# Random Forest N = 3\n",
    "clf = RandomForestClassifier(n_estimators=5, max_features=None)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='#2b84ad', label='RF N=5 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "# Random Forest N = 5\n",
    "clf = RandomForestClassifier(n_estimators=10, max_features=None)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='#8138a0', label='RF N=5 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "# Random Forest N = 10\n",
    "clf = RandomForestClassifier(n_estimators=15, max_features=None)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='pink', label='RF N=15 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20, max_features=None)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='#cc5d94', label='RF N=20 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=5000, max_features=None)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='#d63384', label='RF N=5000 ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.ylim([0.6, 1.00])\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 0.1])\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title('ROC for various methods')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We could see that the random forest classifier with N=10 and above performed the best. Because Random Forest can also give the measures of how the useful each feature was, we can draw the simple histogram that shows feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest N = 10\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "col = pd.DataFrame(df_col_merged[:,1: last_col_index], columns=['$\\Delta e_{u-z}$', '$\\Delta \\phi_{u-z}$', 'u-z', '$\\Delta x_{u-z}$', '$\\Delta size_{u-z}$', '$\\Delta \\omega_{u-z}$'])\n",
    "importance = sorted(zip(col.columns.values,clf.feature_importances_),key=lambda q: q[1],reverse=True)\n",
    "row = zip(*importance)[0]\n",
    "column = zip(*importance)[1]\n",
    "x_pos = np.arange(len(row))\n",
    "plt.bar(x_pos, column, align='center', color='#890b22')\n",
    "plt.xticks(x_pos, row)\n",
    "plt.ylabel('Feature importance')\n",
    "\n",
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    " \n",
    "# Calculate the AUC\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
